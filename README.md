## 👩🏻‍💻 프로젝트 소개

> 2025 SISS인의 밤 프로젝트  
> 9조 - 파이썬을 활용한 웹 크롤러 제작

**“구직 사이트 스크래핑 및 CSV 파일 추출 서비스”**

사용자가 원하는 키워드로 잡코리아와 사람인 사이트에서 채용 공고를 크롤링하고,  
검색 결과를 웹 페이지에 시각화하며 `.csv` 파일로 추출할 수 있는 간단한 서비스입니다

---

## ❄️ 9조

| <img src="https://avatars.githubusercontent.com/u/123651373?v=4" width="250" /> |
| :-----------------------------------------------------------------------------: |
|                      [강민지](https://github.com/mingd0d)                       |
|                       크롤링 페이지 분석</br>페이지 구현                        |

---

## 👩🏻‍💻 기술 스택

| 구분       | 사용 도구                   |
| ---------- | --------------------------- |
| 언어       | Python                      |
| 프레임워크 | Flask                       |
| 라이브러리 | BeautifulSoup, cloudscraper |
| 기타 도구  | Notion, Figma               |

---

## 📁 파일 구조

```
📦 project-root/
├─ main.py          # Flask 서버 실행 및 라우팅
├─ 📁 extractors/   # 사이트별 크롤링 모듈
│ ├─ jobkorea.py    # JobKorea 크롤러
│ └─ saramin.py     # Saramin 크롤러
├─ 📁 templates/    # HTML 템플릿
│ ├─ home.html      # 검색 입력 페이지
│ └─ search.html    # 검색 결과 페이지
└─ file.py          # CSV 파일 저장 함수
```

---

## 📝 기능 설명

### 1. **구직 사이트 스크래핑**

- `jobkorea.py`, `saramin.py` 파일을 통해 **잡코리아**와 **사람인**에서 구직 정보를 스크래핑합니다
- 채용공고의 **직무명**, **회사명**, **위치**, **마감일자**(D-일수), **지원 링크**를 추출하여 제공합니다

### 2. **검색 및 결과 출력**

- 사용자가 특정 키워드를 입력하면 관련된 구인 정보를 실시간으로 검색하여 출력합니다
- 출력된 결과는 **직무명**, **회사명**, **위치**, **마감일자**와 함께 **지원 링크**가 포함됩니다

### 3. **CSV 파일 추출**

- 검색된 결과는 `.csv` 형식으로 다운로드가 가능하며, 파일에는 **직무명**, **회사명**, **위치**, **마감일자**, **지원 링크**가 포함됩니다

---

## 📷 실행 화면

| 검색 페이지                                                                                               | 검색 결과                                                                                                 | CSV 추출                                                                                                  |
| --------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- |
| <img width="400" src="https://github.com/user-attachments/assets/0f700941-80d8-41a5-bdb4-9827f0eb034a" /> | <img width="400" src="https://github.com/user-attachments/assets/825a24da-6d0e-42ab-8f8d-93b368fafa78" /> | <img width="400" src="https://github.com/user-attachments/assets/9de2aec0-3bbb-4999-be30-6aadb2bdb875" /> |

---

## 📂 코드 설명

### 1. **`main.py`**

- 웹 크롤러와 서버를 실행하며, 사용자 입력에 따라 크롤링된 정보를 웹페이지로 제공합니다

### 2. **`extractors/jobkorea.py`**

- 잡코리아에서 구직 정보를 스크래핑합니다

### 3. **`extractors/saramin.py`**

- 사람인에서 구직 정보를 스크래핑합니다

### 4. **`file.py`**

- 스크래핑된 데이터를 **CSV** 파일로 저장하는 기능을 제공합니다

---

## 📋 실행 방법

1. **환경 설정**

   - Python 3.x 이상이 설치되어 있어야 합니다
   - 필요한 라이브러리 설치:
     ```bash
     pip install beautifulsoup4 Flask cloudscraper
     ```

2. **서버 실행**

   ```bash
   python main.py
   ```

3. **웹 페이지에서 검색**:

   - `http://127.0.0.1:5000`에서 웹 페이지에 접속하여 검색어를 입력합니다

4. **결과 확인 및 CSV 파일 추출**
   - 검색 후, 결과 확인 페이지로 이동합니다
   - 이후 **Export to file** 버튼을 누르면 .csv 파일로 다운로드할 수 있습니다
